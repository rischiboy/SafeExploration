wandb:
  project_name: "Week-21"                                         # Name of the project on wandb
  group_name: "Safe-CEM-Reset"                                 # Name of the run on wandb
  job_name: "Exploration_200"                                                # Name of the job
  logs_dir: "./experiments/results/pendulum"                      # Directory to save the logs
  logging_wandb: True                                            # Whether to log the training to wandb
env:
  angle_tolerance: 0.1
  stability_duration: 10
  max_steps: 200
  max_speed: 12.0
constraint:
  speed_threshold: 6.0
  lmbda: 100.0
  d: 0.0
cem:
  horizon: 20                       # Planning horizon
  num_iter: 10                      # Number of consecutive CEM update iterations        
  num_elites: 50                    # Number of elite samples considered to update the distribution
  num_samples: 500                  # Total number of samples
model:
  dynamics_type: "BNN"              # ["TRUE", "BNN"]
  agent_type: "CEM"                 # ["CEM", "MinMax"]
  bnn_type: "DeterministicEnsemble" # ["DeterministicEnsemble", "ProbabilisticEnsemble", "DeterministicFSVGDEnsemble", "ProbabilisticFSVGDEnsemble"]
  sampling_mode: "DIST"             # ["MEAN", "NOISY_MEAN", "DIST"]
  output_stds: [0.0001, 0.0001, 0.0001]    # Standard deviation of the output of the model -- ProbabilisticEnsemble
  num_training_steps: 10            # Number of training epochs to fit the BNN model -- BNNStatisticalModel
  beta: [1.0, 1.0, 1.0]             # Constant scheduler -- BNNStatisticalModel
  features: [256, 256]              # Number of hidden units in the MLP
  lr_rate: 0.0001                   # Learning rate for the Adam optimizer
  weight_decay: 0.001               # Weight decay for Adam optimizer
  num_ensembles: 5                  # Number of ensembles for the ensemble model
  num_particles: 10                 # Number of particles to sample from the distribution   
  train_share: 0.8                  # Share of the data used for training
  batch_size: 64                    # Batch size for training the BNN model
  eval_frequency: 5                 # Number of training epochs between evaluation of the model
  eval_batch_size: 2048             # Batch size for evaluating the model
  return_best_model: False          # Whether to return the best model parameters based on the validation loss
train:
  # seed: 0
  sample_batch_size: 256            # Batch size for sampling from the replay buffer
  buffer_size: 30000                # Size of the replay buffer
  num_model_updates: 100             # Number of training iterations
  num_rollout_steps: 200            # Number of steps to rollout the agent
  num_exploration_steps: 200       # Number of steps to collect data for the replay buffer
  val_buffer_size: 500              # Size of the validation buffer
  val_batch_size: 500               # Batch size for evaluating the model
  eval_episodes: 3                  # Number of episodes to evaluate the agent
  eval_model_freq: 10                # Number of training iterations between evaluation
  diff_states: False                # Whether to use the difference between states as input  
  verbose: True                     # Whether to print the training progress  
  render: True                      # Whether to store recordings of the evaluation episodes